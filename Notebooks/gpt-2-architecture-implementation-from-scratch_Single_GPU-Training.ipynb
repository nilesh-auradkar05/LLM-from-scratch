{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12413689,"sourceType":"datasetVersion","datasetId":7829030}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install uv\n!uv venv gpt2-clone\n!source /kaggle/working/gpt2-clone/bin/activate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T02:42:56.880704Z","iopub.execute_input":"2025-07-17T02:42:56.881008Z","iopub.status.idle":"2025-07-17T02:43:02.629417Z","shell.execute_reply.started":"2025-07-17T02:42:56.880984Z","shell.execute_reply":"2025-07-17T02:43:02.628563Z"}},"outputs":[{"name":"stdout","text":"Collecting uv\n  Downloading uv-0.7.21-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading uv-0.7.21-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: uv\nSuccessfully installed uv-0.7.21\n\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\nUsing CPython 3.11.13 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\nCreating virtual environment at: \u001b[36mgpt2-clone\u001b[39m\nActivate with: \u001b[32msource gpt2-clone/bin/activate\u001b[39m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!uv pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!uv pip install -q huggingface tiktoken datasets transformers tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T02:43:02.631061Z","iopub.execute_input":"2025-07-17T02:43:02.631343Z","iopub.status.idle":"2025-07-17T02:43:48.034412Z","shell.execute_reply.started":"2025-07-17T02:43:02.631321Z","shell.execute_reply":"2025-07-17T02:43:48.033515Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T02:43:48.035340Z","iopub.execute_input":"2025-07-17T02:43:48.035541Z","iopub.status.idle":"2025-07-17T02:43:48.317727Z","shell.execute_reply.started":"2025-07-17T02:43:48.035520Z","shell.execute_reply":"2025-07-17T02:43:48.317066Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/shakesphere-book/shakesphere_book.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom datasets import load_dataset\nfrom transformers import get_cosine_schedule_with_warmup\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T02:43:48.319864Z","iopub.execute_input":"2025-07-17T02:43:48.320628Z","iopub.status.idle":"2025-07-17T02:43:55.508284Z","shell.execute_reply.started":"2025-07-17T02:43:48.320606Z","shell.execute_reply":"2025-07-17T02:43:55.507419Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Dataset Preparation","metadata":{}},{"cell_type":"code","source":"# Downloading Dataset\ndef load_bookcorpus():\n    full_book_corpus = load_dataset(\"bookcorpus\", trust_remote_code=True)\n\n    if \"train\" in full_book_corpus:\n        full_dataset = full_book_corpus[\"train\"]\n        total_dataset_size = len(full_dataset)\n        print(f\"Total Dataset Size: {full_dataset}\")\n        print(\"Extracting subset of 10,000,000\")\n        book_corpus = full_dataset.select(range(500_000))\n        print(f\"Final Dataset Size after Cropping: {len(book_corpus)}\")\n        first_example = book_corpus[0]\n        key = list(first_example.keys())[0]\n        for i in range(10):\n            print(book_corpus[i][key])\n        return book_corpus\n    else:\n        print(\"The dataset has no training split.\")\n        book_corpus = full_book_corpus.select(range(500_000))\n        return book_corpus","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T02:43:55.516079Z","iopub.execute_input":"2025-07-17T02:43:55.516588Z","iopub.status.idle":"2025-07-17T02:43:55.535955Z","shell.execute_reply.started":"2025-07-17T02:43:55.516569Z","shell.execute_reply":"2025-07-17T02:43:55.535175Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"torch.manual_seed(47)\nbook_corpus = load_bookcorpus()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T02:43:55.536730Z","iopub.execute_input":"2025-07-17T02:43:55.536990Z","execution_failed":"2025-07-17T03:34:44.816Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c4a7b03e1a44481b0657833b906ce86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bookcorpus.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e070bb08f5240ff930f5cb59879b23c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27fb87800a5d45d9b1346ac1890bb70e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/74004228 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"043015f863b64b9dbd3015fb5614a833"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"# GPT-2 Architecture Implementation","metadata":{}},{"cell_type":"code","source":"GPT2_CONFIG_124M = {\n    \"vocab_size\": 50257,\n    \"context_length\": 512,\n    \"embedding_dim\": 768,\n    \"num_heads\": 12,\n    \"num_layers\": 12,\n    \"drop_rate\": 0.1,\n    \"qkv_bias\": False,\n}","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Layer Normalization Block","metadata":{}},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self, embedding_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(embedding_dim))\n        self.shift = nn.Parameter(torch.zeros(embedding_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / (torch.sqrt(var + self.eps))\n        return self.scale * norm_x + self.shift","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feed-Forward Block","metadata":{}},{"cell_type":"code","source":"# GELU implementation\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n            (x + 0.044715 * torch.pow(x, 3))\n        ))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FeedForwardNNBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"embedding_dim\"], 4 * cfg[\"embedding_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"embedding_dim\"], cfg[\"embedding_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Multi-Head Attention Block","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert (d_out % num_heads == 0), \\\n            \"d_out should be divisble by num_heads\"\n        \n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads\n\n        # initializing weight matrices\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.out_proj = nn.Linear(d_out, d_out)\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\n            \"mask\",\n            torch.triu(\n                torch.ones(context_length, context_length),\n                diagonal=1\n            )\n        )\n\n    def forward(self, x):\n        batch_size, num_tokens, d_in = x.shape\n\n        # input * weight matrices\n        queries = self.W_query(x)\n        keys = self.W_key(x)\n        values = self.W_value(x)\n\n        # Roll out last dim \"d_out\" to num_heads and head_dim\n        # (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n        queries = queries.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n        keys = keys.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n        values = values.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n\n        # Transpose to (b, num_heads, num_tokens, head_dim)\n        queries = queries.transpose(1, 2)\n        keys = keys.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        # Compute Attention scores\n        attn_scores = queries @ keys.transpose(2, 3)\n\n        # mask future tokens\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n        attn_scores.masked_fill(mask_bool, -torch.inf)\n\n        # Compute Attention Weights\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Compute Context Vector Matrix\n        context_vec = (attn_weights @ values).transpose(1, 2)\n        context_vec = context_vec.contiguous().view(batch_size, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)\n\n        return context_vec","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transformer Block","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.mask_attn = MultiHeadAttention(\n            d_in=cfg[\"embedding_dim\"],\n            d_out=cfg[\"embedding_dim\"],\n            context_length=cfg[\"context_length\"],\n            dropout=cfg[\"drop_rate\"],\n            num_heads=cfg[\"num_heads\"],\n            qkv_bias=cfg[\"qkv_bias\"],\n        )\n        self.ffn_block = FeedForwardNNBlock(cfg)\n        self.norm_1 = LayerNormalization(cfg[\"embedding_dim\"])\n        self.norm_2 = LayerNormalization(cfg[\"embedding_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n        # Block 1\n        # residual connection for attention block\n        shortcut = x\n        x = self.norm_1(x)\n        x = self.mask_attn(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        # Block 2\n        shortcut = x\n        x = self.norm_2(x)\n        x = self.ffn_block(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        return x","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GPT2Model(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_embeddings = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embedding_dim\"])\n        self.pos_embeddings = nn.Embedding(cfg[\"context_length\"], cfg[\"embedding_dim\"])\n        self.drop_embeddings = nn.Dropout(cfg[\"drop_rate\"])\n\n        self.transformer_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"num_layers\"])]\n        )\n\n        self.final_norm = LayerNormalization(cfg[\"embedding_dim\"])\n        self.out_head = nn.Linear(\n            cfg[\"embedding_dim\"], cfg[\"vocab_size\"], bias=False\n        )\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeddings = self.tok_embeddings(in_idx)\n        pos_embeddings = self.pos_embeddings(torch.arange(seq_len, device=in_idx.device))\n\n        x = tok_embeddings + pos_embeddings\n        x = self.drop_embeddings(x)\n        x = self.transformer_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Initialization","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(47)\nmodel = GPT2Model(GPT2_CONFIG_124M)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"total number of parameters in the model: {total_params:,}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gpt_2_model_params = total_params - sum(p.numel() for p in model.out_head.parameters())\nprint(f\"Total Architecture trainable parameters without output head weights: {gpt_2_model_params:,}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Logits to output tokens.","metadata":{}},{"cell_type":"code","source":"def generate_text_v1(model, idx, max_new_tokens, context_size):\n    \"\"\"Get last row from logits for each bach. fetch token with max value. \n        Append to input and repeat.\n        Optional: Convert token id to text and display the generated text.\n    \"\"\"\n    for _ in range(max_new_tokens):\n\n        # 1. truncate input if larger than context size\n        idx_cond = idx[:, -context_size:]\n\n        # 2. Get the predictions\n        with torch.no_grad():\n            logits = model(idx_cond)\n\n        # 3. Retrive only the last row from each batch\n        logits = logits[:, -1, :]\n\n        # 4. Applying softmax to logits\n        probas = torch.softmax(logits, dim=-1)\n\n        # 5. Get index of the vocab entry with the highest probability\n        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n\n        # 6. Append Retrived token id to original input\n        idx = torch.cat((idx, idx_next), dim=1)\n\n    return idx","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Token Embedding Shape: {model.tok_embeddings.weight.shape}\")\nprint(f\"Output layer shape: {model.out_head.weight.shape}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating DataLoaders","metadata":{}},{"cell_type":"code","source":"# Creating Dataset for training.\nimport tiktoken\nfrom torch.utils.data import Dataset, DataLoader\n\nclass BookCorpusDataset(Dataset):\n    def __init__(self, book_corpus, tokenizer, context_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Joining iterable dict into a string\n        print(\"Tokenizing and Chunking data...\")\n        all_text = [\n            content['text'] for content in tqdm(book_corpus, desc=\"üìö Reading examples\")\n        ]\n        full_text = \" \".join(all_text)\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(full_text, allowed_special={\"<|endoftext|>\"})\n        total_tokens = len(token_ids)\n\n        # sliding window approach to chunk the text as input and output tokens of context_size\n        for i in range(0, len(token_ids) - context_length, stride):\n            input_chunk = token_ids[i : i+context_length]\n            target_chunk = token_ids[i+1 : i+context_length+1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]\n\ndef create_dataloader(book_corpus, batch_size=4, context_length=512,\n                      stride=512, shuffle=True, drop_last=True, num_workers=0):\n\n    try:\n        # initializing tokenizer\n        tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n        # creating dataset\n        dataset = BookCorpusDataset(book_corpus, tokenizer, context_length, stride)\n\n        # create dataloader\n        dataloader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            drop_last=drop_last,\n            pin_memory=True,\n            num_workers=num_workers\n        )\n\n        return dataloader\n    except Exception as e:\n        print(e)\n    \n    ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Info about dataset\ntrain_ratio = 0.75\ntest_ratio = 0.25\ntotal_dataset_size = len(book_corpus)\nsplit_dataset = book_corpus.train_test_split(test_size=test_ratio, seed=47)\n# splitting training set to train and validate\ntrain_data = split_dataset['train']\nvalidation_data = split_dataset['test']\nprint(\"Size of Train set: \", len(train_data))\nprint(\"Size of Validation set: \", len(validation_data))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = create_dataloader(\n    train_data,\n    batch_size=4,\n    context_length=GPT2_CONFIG_124M[\"context_length\"],\n    stride=GPT2_CONFIG_124M[\"context_length\"],\n    drop_last=True,\n    shuffle=True,\n    num_workers=0,\n)\n\nval_loader = create_dataloader(\n    validation_data,\n    batch_size=4,\n    context_length=GPT2_CONFIG_124M[\"context_length\"],\n    stride=GPT2_CONFIG_124M[\"context_length\"],\n    drop_last=False,\n    shuffle=False,\n    num_workers=0,\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sanity checks before Training","metadata":{}},{"cell_type":"code","source":"sample_tokenizer = tiktoken.get_encoding(\"gpt2\")\ntotal_tokens = sample_tokenizer.encode(book_corpus['text'][:])\nprint(\"Total_tokens : \", total_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:57.398803Z","iopub.execute_input":"2025-07-16T19:41:57.399066Z","iopub.status.idle":"2025-07-16T19:41:57.541141Z","shell.execute_reply.started":"2025-07-16T19:41:57.399049Z","shell.execute_reply":"2025-07-16T19:41:57.540215Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3638225196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total_tokens : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tiktoken/core.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_special_token_regex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0mraise_disallowed_special_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected string or buffer"],"ename":"TypeError","evalue":"expected string or buffer","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"# Sanity Checks\nif total_tokens * (train_ratio) < GPT2_CONFIG_124M[\"context_length\"]:\n    print(\"Not enough tokens for training loader. Try to lower GPT2_CONFIG_124M['context_length']\")\n\nif total_tokens * (1 - train_ratio) < GPT2_CONFIG_124M[\"context_length\"]:\n    print(\"Not enough tokens for validation set.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Examining Input and target matrices.","metadata":{}},{"cell_type":"code","source":"print(\"Train loader: \")\nfor x, y in train_loader:\n    print(x.shape, y.shape)\n\nprint(\"Validation loader: \")\nfor x, y in val_loader:\n    print(x.shape, y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:08.578792Z","iopub.execute_input":"2025-07-16T19:42:08.579525Z","iopub.status.idle":"2025-07-16T19:42:09.658184Z","shell.execute_reply.started":"2025-07-16T19:42:08.579494Z","shell.execute_reply":"2025-07-16T19:42:09.657298Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Train loader: \ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\nValidation loader: \ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([3, 512]) torch.Size([3, 512])\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Loss function for model evaluation","metadata":{}},{"cell_type":"code","source":"def calculate_loss_batch(input_batch, target_batch, model, device):\n    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\ndef calculate_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        # reduce number of batches to match number of batches in the data loader\n        num_batches = min(num_batches, len(data_loader))\n\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n            total_loss += loss.item()\n            \n        else:\n            break\n    return total_loss / num_batches","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    # disable Dropout layer\n    model.eval()\n\n    # Get predictions\n    with torch.no_grad():\n        train_loss = calculate_loss_loader(train_loader, model, device, num_batches=eval_iter)\n        val_loss = calculate_loss_loader(val_loader, model, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate and Print Sample","metadata":{}},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0)\n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_embeddings.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text(\n            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n        )\n\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:02:30.802416Z","iopub.execute_input":"2025-07-16T23:02:30.803038Z","iopub.status.idle":"2025-07-16T23:02:30.807149Z","shell.execute_reply.started":"2025-07-16T23:02:30.803003Z","shell.execute_reply":"2025-07-16T23:02:30.806509Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"def train_model_v1(model, train_loader, val_loader, optimizer,\n          device, num_epochs, eval_freq, eval_iter,\n          start_context, tokenizer):\n\n    # initlization of lists to track losses and token seen\n    train_losses = val_losses = track_tokens_seen = []\n    tokens_seen, global_step = 0, -1\n\n    # Main loop\n    # For each epoch\n    for epoch in range(num_epochs):\n        model.train()\n\n        # For each batch in epoch\n        for input_batch, target_batch in train_loader:\n            # Reset loss gradients from previous batch\n            optimizer.zero_grad()\n\n            # calculate loss\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n\n            # compute gradient loss\n            loss.backward()\n\n            # update weights\n            optimizer.step()\n\n            # update tokens seen at step\n            tokens_seen += input_batch.numel()\n\n            # update epoch count\n            global_step += 1\n\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter\n                )\n\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Epoch: {epoch+1} (Step {global_step:06d}): \"\n                      f\"Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n\n        # generate output from tokens for visualization after each epoch\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:02:33.439743Z","iopub.execute_input":"2025-07-16T23:02:33.440312Z","iopub.status.idle":"2025-07-16T23:02:33.445998Z","shell.execute_reply.started":"2025-07-16T23:02:33.440290Z","shell.execute_reply":"2025-07-16T23:02:33.445232Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def train_model_v2(model, train_loader, val_loader, optimizer,\n          scheduler, device, num_epochs, eval_freq, eval_iter,\n          start_context, tokenizer):\n\n    # initlization of lists to track losses and token seen\n    train_losses = val_losses = track_tokens_seen = []\n    tokens_seen, global_step = 0, -1\n\n    # Main loop\n    # For each epoch\n    for epoch in range(num_epochs):\n        model.train()\n\n        total_train_loss = 0\n\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n\n        # For each batch in epoch\n        for input_batch, target_batch in progress_bar:\n            # Reset loss gradients from previous batch\n            optimizer.zero_grad()\n\n            # calculate loss\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n\n            # compute gradient loss\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # update weights\n            optimizer.step()\n            scheduler.step()\n\n            total_train_loss += loss.item()\n            # update tokens seen at step\n            tokens_seen += input_batch.numel()\n\n            # update step count\n            # global_step += 1\n            progress_bar.set_postfix({\"loss\": f\"{loss.item():.3f}\"})\n\n        # Evaluation after each epoch\n        model.eval()\n        with torch.no_grad():\n            val_loss = calculate_loss_loader(val_loader, model, device)\n\n        # avg training loss for each epoch\n        avg_train_loss = total_train_loss / len(train_loader)\n\n        train_losses.append(avg_train_loss)\n        val_losses.append(val_loss)\n\n        print(f\"Epoch {epoch+1:02d} | Avg Train Loss: {avg_train_loss:.3f} | Val loss: {val_loss:.3f}\")\n\n        # generate output from tokens for visualization after each epoch\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:02:41.539368Z","iopub.execute_input":"2025-07-16T23:02:41.540081Z","iopub.status.idle":"2025-07-16T23:02:41.546370Z","shell.execute_reply.started":"2025-07-16T23:02:41.540053Z","shell.execute_reply":"2025-07-16T23:02:41.545658Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"if torch.cuda.is_available():\n   device = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n   device = torch.device(\"mps\")\nelse:\n   device = torch.device(\"cpu\")\n\nprint(f\"Using {device} device.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\nnum_epochs = 5\n\ntotal_training_steps = num_epochs * len(train_loader)\nwarmup_steps = int(total_training_steps * 0.1)\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_training_steps,\n)\n\ntrain_losses, val_losses, tokens_seen = train_model_v2(\n    model, train_loader, val_loader, optimizer, scheduler, \n    device, num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n    start_context=\"he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins \", tokenizer=tokenizer\n)\n\nend_time = time.time()\nexecution_time = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time:.2f} minutes.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:58:03.787849Z","iopub.execute_input":"2025-07-16T19:58:03.788321Z","iopub.status.idle":"2025-07-16T20:16:03.463859Z","shell.execute_reply.started":"2025-07-16T19:58:03.788297Z","shell.execute_reply":"2025-07-16T20:16:03.462821Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/5:   0%|          | 0/572 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 01 | Avg Train Loss: 2.919 | Val loss: 0.481\nEvery effort moves you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/5:   0%|          | 0/572 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 02 | Avg Train Loss: 0.271 | Val loss: 0.135\nEvery effort moves you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/5:   0%|          | 0/572 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 03 | Avg Train Loss: 0.072 | Val loss: 0.092\nEvery effort moves you big you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/5:   0%|          | 0/572 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 04 | Avg Train Loss: 0.032 | Val loss: 0.084\nEvery effort moves you moves you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/5:   0%|          | 0/572 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 05 | Avg Train Loss: 0.021 | Val loss: 0.084\nEvery effort moves you moves you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\nTraining completed in 17.99 minutes.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## Temperature Scaling + Selecting Top-k Logits for Output Tokens ","metadata":{}},{"cell_type":"code","source":"def generate_text(model, idx, max_new_tokens, context_size, temperature=0.7, top_k=5, eos_id=None):\n\n    # 1. Get Logits.\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1, :]\n\n        # 2. Select Top_k elements\n        if top_k is not None:\n            top_logits, idx_numbers = torch.topk(logits, top_k)\n            # 3. Set all other logits except top k to -inf\n            min_val = top_logits[:, -1]\n            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n\n        # 3. Scale by temperature value\n        if temperature > 0.0:\n            logits = logits / temperature\n\n            # 4. Apply softmax\n            probs = torch.softmax(logits, dim=-1)\n\n            # 5. Sample from Multinomial distribution\n            idx_next = torch.multinomial(probs, num_samples=1)\n\n        else:\n            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n\n        if idx_next == eos_id:\n            break\n\n        idx = torch.cat((idx, idx_next), dim=1)\n\n    return idx","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model_v3(model, train_loader, val_loader, optimizer,\n          scheduler, device, num_epochs, eval_freq, eval_iter,\n          start_context, tokenizer):\n\n    # initlization of lists to track losses and token seen\n    train_losses = val_losses = track_tokens_seen = []\n    tokens_seen = 0\n\n    # Main loop\n    # For each epoch\n    for epoch in range(num_epochs):\n        model.train()\n        total_train_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n\n        # For each batch in epoch\n        for input_batch, target_batch in progress_bar:\n            # Reset loss gradients from previous batch\n            optimizer.zero_grad()\n\n            # calculate loss\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n\n            # compute gradient loss\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # update weights\n            optimizer.step()\n            scheduler.step()\n\n            total_train_loss += loss.item()\n            # update tokens seen at step\n            tokens_seen += input_batch.numel()\n\n            progress_bar.set_postfix({\"loss\": f\"{loss.item():.3f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.1e}\"})\n\n        # Evaluation after each epoch\n        model.eval()\n        with torch.no_grad():\n            val_loss = calculate_loss_loader(val_loader, model, device)\n\n        # avg training loss for each epoch\n        avg_train_loss = total_train_loss / len(train_loader)\n\n        train_losses.append(avg_train_loss)\n        val_losses.append(val_loss)\n\n        print(f\"Epoch {epoch+1:02d} | Avg Train Loss: {avg_train_loss:.3f} | Val loss: {val_loss:.3f}\")\n\n        # generate output from tokens for visualization after each epoch\n        start_ids = text_to_token_ids(start_context, tokenizer).to(device)\n        context_size = model.pos_embeddings.weight.shape[0]\n\n        with torch.no_grad():\n            output_ids = generate_text(\n                model=model,\n                idx=start_ids,\n                max_new_tokens=50,\n                context_size=context_size,\n                top_k=50,\n            )\n\n        generated_text = token_ids_to_text(output_ids, tokenizer)\n        print(f\"Sample: {generated_text.replace(chr(10), ' ')}\")\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\nnum_epochs = 30\n\ntotal_training_steps = num_epochs * len(train_loader)\nwarmup_steps = int(total_training_steps * 0.1)\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_training_steps,\n)\n\ntrain_losses, val_losses, tokens_seen = train_model_v3(\n    model, train_loader, val_loader, optimizer, scheduler, \n    device, num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n    start_context=\"Every effort moves you \", tokenizer=tokenizer\n)\n\nend_time = time.time()\nexecution_time = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time:.2f} minutes.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-17T03:34:44.818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saving Trained Model Weights","metadata":{}},{"cell_type":"code","source":"torch.save({\n    \"model_state_dict\": model.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict()\n    },\n    \"pre-trained_llm_and_optimizer.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}