{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12413689,"sourceType":"datasetVersion","datasetId":7829030}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install uv\n!uv venv gpt2-clone\n!source /kaggle/working/gpt2-clone/bin/activate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:21:19.233008Z","iopub.execute_input":"2025-07-16T19:21:19.233249Z","iopub.status.idle":"2025-07-16T19:21:26.495699Z","shell.execute_reply.started":"2025-07-16T19:21:19.233230Z","shell.execute_reply":"2025-07-16T19:21:26.494895Z"}},"outputs":[{"name":"stdout","text":"Collecting uv\n  Downloading uv-0.7.21-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading uv-0.7.21-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: uv\nSuccessfully installed uv-0.7.21\n\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\nUsing CPython 3.11.13 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\nCreating virtual environment at: \u001b[36mgpt2-clone\u001b[39m\nActivate with: \u001b[32msource gpt2-clone/bin/activate\u001b[39m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!uv pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!uv pip install -q huggingface tiktoken datasets transformers tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:21:53.120196Z","iopub.execute_input":"2025-07-16T19:21:53.120484Z","iopub.status.idle":"2025-07-16T19:22:40.856099Z","shell.execute_reply.started":"2025-07-16T19:21:53.120457Z","shell.execute_reply":"2025-07-16T19:22:40.855296Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:23:02.520222Z","iopub.execute_input":"2025-07-16T19:23:02.520477Z","iopub.status.idle":"2025-07-16T19:23:02.811751Z","shell.execute_reply.started":"2025-07-16T19:23:02.520455Z","shell.execute_reply":"2025-07-16T19:23:02.811128Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/shakesphere-book/shakesphere_book.txt\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom datasets import load_dataset\nfrom transformers import get_cosine_schedule_with_warmup\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:23:41.485782Z","iopub.execute_input":"2025-07-16T19:23:41.486055Z","iopub.status.idle":"2025-07-16T19:23:47.423676Z","shell.execute_reply.started":"2025-07-16T19:23:41.486036Z","shell.execute_reply":"2025-07-16T19:23:47.423101Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Dataset Preparation","metadata":{}},{"cell_type":"code","source":"# Downloading Dataset\ndef load_bookcorpus():\n    full_book_corpus = load_dataset(\"bookcorpus\", trust_remote_code=True)\n\n    if \"train\" in full_book_corpus:\n        full_dataset = full_book_corpus[\"train\"]\n        total_dataset_size = len(full_dataset)\n        print(f\"Total Dataset Size: {full_dataset}\")\n        print(\"Extracting subset of 10,000,000\")\n        book_corpus = full_dataset.select(range(100_000))\n        print(f\"Final Dataset Size after Cropping: {len(book_corpus)}\")\n        first_example = book_corpus[0]\n        key = list(first_example.keys())[0]\n        for i in range(10):\n            print(book_corpus[i][key])\n        return book_corpus\n    else:\n        print(\"The dataset has no training split.\")\n        book_corpus = full_book_corpus.select(range(100_000))\n        return book_corpus","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:23:04.754235Z","iopub.execute_input":"2025-07-16T19:23:04.755124Z","iopub.status.idle":"2025-07-16T19:23:04.760129Z","shell.execute_reply.started":"2025-07-16T19:23:04.755101Z","shell.execute_reply":"2025-07-16T19:23:04.759391Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"torch.manual_seed(47)\nbook_corpus = load_bookcorpus()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:23:54.102561Z","iopub.execute_input":"2025-07-16T19:23:54.103022Z","iopub.status.idle":"2025-07-16T19:40:20.572563Z","shell.execute_reply.started":"2025-07-16T19:23:54.102989Z","shell.execute_reply":"2025-07-16T19:40:20.571936Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25153cf761a945a291d33a6a26dc0a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bookcorpus.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb61ca0ecfa04fa99d9495ad349f96b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420cd9ec3e8042d3acf63e34194a58e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/74004228 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4793784d0e04cd6a19b9f55bdbb5be3"}},"metadata":{}},{"name":"stdout","text":"Total Dataset Size: Dataset({\n    features: ['text'],\n    num_rows: 74004228\n})\nExtracting subset of 10,000,000\nFinal Dataset Size after Cropping: 100000\nusually , he would be tearing around the living room , playing with his toys .\nbut just one look at a minion sent him practically catatonic .\nthat had been megan 's plan when she got him dressed earlier .\nhe 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\nshe liked to think being surrounded by adults and older kids was one reason why he was a such a good talker for his age .\n`` are n't you being a good boy ? ''\nshe said .\nmason barely acknowledged her .\ninstead , his baby blues remained focused on the television .\nsince the movie was almost over , megan knew she better slip into the bedroom and finish getting ready .\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# GPT-2 Architecture Implementation","metadata":{}},{"cell_type":"code","source":"GPT2_CONFIG_124M = {\n    \"vocab_size\": 50257,\n    \"context_length\": 512,\n    \"embedding_dim\": 768,\n    \"num_heads\": 12,\n    \"num_layers\": 12,\n    \"drop_rate\": 0.1,\n    \"qkv_bias\": False,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:40.716913Z","iopub.execute_input":"2025-07-16T19:40:40.717671Z","iopub.status.idle":"2025-07-16T19:40:40.721400Z","shell.execute_reply.started":"2025-07-16T19:40:40.717646Z","shell.execute_reply":"2025-07-16T19:40:40.720569Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Layer Normalization Block","metadata":{}},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self, embedding_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(embedding_dim))\n        self.shift = nn.Parameter(torch.zeros(embedding_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / (torch.sqrt(var + self.eps))\n        return self.scale * norm_x + self.shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:43.725205Z","iopub.execute_input":"2025-07-16T19:40:43.725482Z","iopub.status.idle":"2025-07-16T19:40:43.730744Z","shell.execute_reply.started":"2025-07-16T19:40:43.725460Z","shell.execute_reply":"2025-07-16T19:40:43.729898Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### Feed-Forward Block","metadata":{}},{"cell_type":"code","source":"# GELU implementation\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n            (x + 0.044715 * torch.pow(x, 3))\n        ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:46.542094Z","iopub.execute_input":"2025-07-16T19:40:46.542364Z","iopub.status.idle":"2025-07-16T19:40:46.546512Z","shell.execute_reply.started":"2025-07-16T19:40:46.542346Z","shell.execute_reply":"2025-07-16T19:40:46.545767Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class FeedForwardNNBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"embedding_dim\"], 4 * cfg[\"embedding_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"embedding_dim\"], cfg[\"embedding_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:47.867351Z","iopub.execute_input":"2025-07-16T19:40:47.868109Z","iopub.status.idle":"2025-07-16T19:40:47.872334Z","shell.execute_reply.started":"2025-07-16T19:40:47.868083Z","shell.execute_reply":"2025-07-16T19:40:47.871770Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Multi-Head Attention Block","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert (d_out % num_heads == 0), \\\n            \"d_out should be divisble by num_heads\"\n        \n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads\n\n        # initializing weight matrices\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.out_proj = nn.Linear(d_out, d_out)\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\n            \"mask\",\n            torch.triu(\n                torch.ones(context_length, context_length),\n                diagonal=1\n            )\n        )\n\n    def forward(self, x):\n        batch_size, num_tokens, d_in = x.shape\n\n        # input * weight matrices\n        queries = self.W_query(x)\n        keys = self.W_key(x)\n        values = self.W_value(x)\n\n        # Roll out last dim \"d_out\" to num_heads and head_dim\n        # (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n        queries = queries.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n        keys = keys.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n        values = values.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n\n        # Transpose to (b, num_heads, num_tokens, head_dim)\n        queries = queries.transpose(1, 2)\n        keys = keys.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        # Compute Attention scores\n        attn_scores = queries @ keys.transpose(2, 3)\n\n        # mask future tokens\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n        attn_scores.masked_fill(mask_bool, -torch.inf)\n\n        # Compute Attention Weights\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Compute Context Vector Matrix\n        context_vec = (attn_weights @ values).transpose(1, 2)\n        context_vec = context_vec.contiguous().view(batch_size, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)\n\n        return context_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:49.612452Z","iopub.execute_input":"2025-07-16T19:40:49.613032Z","iopub.status.idle":"2025-07-16T19:40:49.620918Z","shell.execute_reply.started":"2025-07-16T19:40:49.613008Z","shell.execute_reply":"2025-07-16T19:40:49.620165Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Transformer Block","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.mask_attn = MultiHeadAttention(\n            d_in=cfg[\"embedding_dim\"],\n            d_out=cfg[\"embedding_dim\"],\n            context_length=cfg[\"context_length\"],\n            dropout=cfg[\"drop_rate\"],\n            num_heads=cfg[\"num_heads\"],\n            qkv_bias=cfg[\"qkv_bias\"],\n        )\n        self.ffn_block = FeedForwardNNBlock(cfg)\n        self.norm_1 = LayerNormalization(cfg[\"embedding_dim\"])\n        self.norm_2 = LayerNormalization(cfg[\"embedding_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n        # Block 1\n        # residual connection for attention block\n        shortcut = x\n        x = self.norm_1(x)\n        x = self.mask_attn(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        # Block 2\n        shortcut = x\n        x = self.norm_2(x)\n        x = self.ffn_block(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:52.467077Z","iopub.execute_input":"2025-07-16T19:40:52.467349Z","iopub.status.idle":"2025-07-16T19:40:52.473413Z","shell.execute_reply.started":"2025-07-16T19:40:52.467329Z","shell.execute_reply":"2025-07-16T19:40:52.472583Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class GPT2Model(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_embeddings = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embedding_dim\"])\n        self.pos_embeddings = nn.Embedding(cfg[\"context_length\"], cfg[\"embedding_dim\"])\n        self.drop_embeddings = nn.Dropout(cfg[\"drop_rate\"])\n\n        self.transformer_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"num_layers\"])]\n        )\n\n        self.final_norm = LayerNormalization(cfg[\"embedding_dim\"])\n        self.out_head = nn.Linear(\n            cfg[\"embedding_dim\"], cfg[\"vocab_size\"], bias=False\n        )\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeddings = self.tok_embeddings(in_idx)\n        pos_embeddings = self.pos_embeddings(torch.arange(seq_len, device=in_idx.device))\n\n        x = tok_embeddings + pos_embeddings\n        x = self.drop_embeddings(x)\n        x = self.transformer_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:40:54.471875Z","iopub.execute_input":"2025-07-16T19:40:54.472556Z","iopub.status.idle":"2025-07-16T19:40:54.478154Z","shell.execute_reply.started":"2025-07-16T19:40:54.472529Z","shell.execute_reply":"2025-07-16T19:40:54.477524Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Model Initialization","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(47)\nmodel = GPT2Model(GPT2_CONFIG_124M)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:18.492309Z","iopub.execute_input":"2025-07-16T19:41:18.492907Z","iopub.status.idle":"2025-07-16T19:41:19.849377Z","shell.execute_reply.started":"2025-07-16T19:41:18.492883Z","shell.execute_reply":"2025-07-16T19:41:19.848830Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"total number of parameters in the model: {total_params:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:20.742032Z","iopub.execute_input":"2025-07-16T19:41:20.742299Z","iopub.status.idle":"2025-07-16T19:41:20.746992Z","shell.execute_reply.started":"2025-07-16T19:41:20.742280Z","shell.execute_reply":"2025-07-16T19:41:20.746375Z"}},"outputs":[{"name":"stdout","text":"total number of parameters in the model: 162,616,320\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"gpt_2_model_params = total_params - sum(p.numel() for p in model.out_head.parameters())\nprint(f\"Total Architecture trainable parameters without output head weights: {gpt_2_model_params:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:21.013355Z","iopub.execute_input":"2025-07-16T19:41:21.013554Z","iopub.status.idle":"2025-07-16T19:41:21.018280Z","shell.execute_reply.started":"2025-07-16T19:41:21.013539Z","shell.execute_reply":"2025-07-16T19:41:21.017623Z"}},"outputs":[{"name":"stdout","text":"Total Architecture trainable parameters without output head weights: 124,018,944\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Logits to output tokens.","metadata":{}},{"cell_type":"code","source":"def generate_text(model, idx, max_new_tokens, context_size):\n    \"\"\"Get last row from logits for each bach. fetch token with max value. \n        Append to input and repeat.\n        Optional: Convert token id to text and display the generated text.\n    \"\"\"\n    for _ in range(max_new_tokens):\n\n        # 1. truncate input if larger than context size\n        idx_cond = idx[:, -context_size:]\n\n        # 2. Get the predictions\n        with torch.no_grad():\n            logits = model(idx_cond)\n\n        # 3. Retrive only the last row from each batch\n        logits = logits[:, -1, :]\n\n        # 4. Applying softmax to logits\n        probas = torch.softmax(logits, dim=-1)\n\n        # 5. Get index of the vocab entry with the highest probability\n        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n\n        # 6. Append Retrived token id to original input\n        idx = torch.cat((idx, idx_next), dim=1)\n\n    return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:23.522332Z","iopub.execute_input":"2025-07-16T19:41:23.523030Z","iopub.status.idle":"2025-07-16T19:41:23.527972Z","shell.execute_reply.started":"2025-07-16T19:41:23.523003Z","shell.execute_reply":"2025-07-16T19:41:23.527280Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(f\"Token Embedding Shape: {model.tok_embeddings.weight.shape}\")\nprint(f\"Output layer shape: {model.out_head.weight.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:26.325911Z","iopub.execute_input":"2025-07-16T19:41:26.326614Z","iopub.status.idle":"2025-07-16T19:41:26.330387Z","shell.execute_reply.started":"2025-07-16T19:41:26.326571Z","shell.execute_reply":"2025-07-16T19:41:26.329748Z"}},"outputs":[{"name":"stdout","text":"Token Embedding Shape: torch.Size([50257, 768])\nOutput layer shape: torch.Size([50257, 768])\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Creating DataLoaders","metadata":{}},{"cell_type":"code","source":"# Creating Dataset for training.\nimport tiktoken\nfrom torch.utils.data import Dataset, DataLoader\n\nclass BookCorpusDataset(Dataset):\n    def __init__(self, book_corpus, tokenizer, context_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Joining iterable dict into a string\n        print(\"Tokenizing and Chunking data...\")\n        all_text = [\n            content['text'] for content in tqdm(book_corpus, desc=\"📚 Reading examples\")\n        ]\n        full_text = \" \".join(all_text)\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(full_text, allowed_special={\"<|endoftext|>\"})\n        total_tokens = len(token_ids)\n\n        # sliding window approach to chunk the text as input and output tokens of context_size\n        for i in range(0, len(token_ids) - context_length, stride):\n            input_chunk = token_ids[i : i+context_length]\n            target_chunk = token_ids[i+1 : i+context_length+1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]\n\ndef create_dataloader(book_corpus, batch_size=4, context_length=512,\n                      stride=512, shuffle=True, drop_last=True, num_workers=0):\n\n    try:\n        # initializing tokenizer\n        tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n        # creating dataset\n        dataset = BookCorpusDataset(book_corpus, tokenizer, context_length, stride)\n\n        # create dataloader\n        dataloader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            drop_last=drop_last,\n            num_workers=num_workers\n        )\n\n        return dataloader\n    except Exception as e:\n        print(e)\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:33.204741Z","iopub.execute_input":"2025-07-16T19:41:33.205419Z","iopub.status.idle":"2025-07-16T19:41:33.228177Z","shell.execute_reply.started":"2025-07-16T19:41:33.205399Z","shell.execute_reply":"2025-07-16T19:41:33.227639Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Info about dataset\ntrain_ratio = 0.75\ntest_ratio = 0.25\ntotal_dataset_size = len(book_corpus)\nsplit_dataset = book_corpus.train_test_split(test_size=test_ratio, seed=47)\n# splitting training set to train and validate\ntrain_data = split_dataset['train']\nvalidation_data = split_dataset['test']\nprint(\"Size of Train set: \", len(train_data))\nprint(\"Size of Validation set: \", len(validation_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:33.521939Z","iopub.execute_input":"2025-07-16T19:41:33.522410Z","iopub.status.idle":"2025-07-16T19:41:33.556582Z","shell.execute_reply.started":"2025-07-16T19:41:33.522390Z","shell.execute_reply":"2025-07-16T19:41:33.555950Z"}},"outputs":[{"name":"stdout","text":"Size of Train set:  75000\nSize of Validation set:  25000\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"train_loader = create_dataloader(\n    train_data,\n    batch_size=4,\n    context_length=GPT2_CONFIG_124M[\"context_length\"],\n    stride=GPT2_CONFIG_124M[\"context_length\"],\n    drop_last=True,\n    shuffle=True,\n    num_workers=2,\n)\n\nval_loader = create_dataloader(\n    validation_data,\n    batch_size=4,\n    context_length=GPT2_CONFIG_124M[\"context_length\"],\n    stride=GPT2_CONFIG_124M[\"context_length\"],\n    drop_last=False,\n    shuffle=False,\n    num_workers=2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:37.830150Z","iopub.execute_input":"2025-07-16T19:41:37.830787Z","iopub.status.idle":"2025-07-16T19:41:47.958165Z","shell.execute_reply.started":"2025-07-16T19:41:37.830764Z","shell.execute_reply":"2025-07-16T19:41:47.957513Z"}},"outputs":[{"name":"stdout","text":"Tokenizing and Chunking data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"📚 Reading examples:   0%|          | 0/75000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e137bcdf1fcd4d45b828212ffdaf7b6e"}},"metadata":{}},{"name":"stdout","text":"Tokenizing and Chunking data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"📚 Reading examples:   0%|          | 0/25000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a802ee006dde4ed1b732ee28c3571d34"}},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Sanity checks before Training","metadata":{}},{"cell_type":"code","source":"sample_tokenizer = tiktoken.get_encoding(\"gpt2\")\ntotal_tokens = sample_tokenizer.encode(book_corpus['text'][:])\nprint(\"Total_tokens : \", total_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:41:57.398803Z","iopub.execute_input":"2025-07-16T19:41:57.399066Z","iopub.status.idle":"2025-07-16T19:41:57.541141Z","shell.execute_reply.started":"2025-07-16T19:41:57.399049Z","shell.execute_reply":"2025-07-16T19:41:57.540215Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3638225196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total_tokens : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tiktoken/core.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_special_token_regex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0mraise_disallowed_special_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected string or buffer"],"ename":"TypeError","evalue":"expected string or buffer","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"# Sanity Checks\nif total_tokens * (train_ratio) < GPT2_CONFIG_124M[\"context_length\"]:\n    print(\"Not enough tokens for training loader. Try to lower GPT2_CONFIG_124M['context_length']\")\n\nif total_tokens * (1 - train_ratio) < GPT2_CONFIG_124M[\"context_length\"]:\n    print(\"Not enough tokens for validation set.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Examining Input and target matrices.","metadata":{}},{"cell_type":"code","source":"print(\"Train loader: \")\nfor x, y in train_loader:\n    print(x.shape, y.shape)\n\nprint(\"Validation loader: \")\nfor x, y in val_loader:\n    print(x.shape, y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:08.578792Z","iopub.execute_input":"2025-07-16T19:42:08.579525Z","iopub.status.idle":"2025-07-16T19:42:09.658184Z","shell.execute_reply.started":"2025-07-16T19:42:08.579494Z","shell.execute_reply":"2025-07-16T19:42:09.657298Z"}},"outputs":[{"name":"stdout","text":"Train loader: \ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\nValidation loader: \ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([4, 512]) torch.Size([4, 512])\ntorch.Size([3, 512]) torch.Size([3, 512])\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Loss function for model evaluation","metadata":{}},{"cell_type":"code","source":"def calculate_loss_batch(input_batch, target_batch, model, device):\n    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\ndef calculate_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        # reduce number of batches to match number of batches in the data loader\n        num_batches = min(num_batches, len(data_loader))\n\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n            total_loss += loss.item()\n            \n        else:\n            break\n    return total_loss / num_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:20.172897Z","iopub.execute_input":"2025-07-16T19:42:20.173856Z","iopub.status.idle":"2025-07-16T19:42:20.179985Z","shell.execute_reply.started":"2025-07-16T19:42:20.173818Z","shell.execute_reply":"2025-07-16T19:42:20.179269Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    # disable Dropout layer\n    model.eval()\n\n    # Get predictions\n    with torch.no_grad():\n        train_loss = calculate_loss_loader(train_loader, model, device, num_batches=eval_iter)\n        val_loss = calculate_loss_loader(val_loader, model, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:40.134770Z","iopub.execute_input":"2025-07-16T19:42:40.135028Z","iopub.status.idle":"2025-07-16T19:42:40.139319Z","shell.execute_reply.started":"2025-07-16T19:42:40.135006Z","shell.execute_reply":"2025-07-16T19:42:40.138655Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Generate and Print Sample","metadata":{}},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special=\"<|endoftext|>\")\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0)\n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:43.688327Z","iopub.execute_input":"2025-07-16T19:42:43.689179Z","iopub.status.idle":"2025-07-16T19:42:43.693431Z","shell.execute_reply.started":"2025-07-16T19:42:43.689150Z","shell.execute_reply":"2025-07-16T19:42:43.692667Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_embeddings.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text(\n            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n        )\n\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:45.569906Z","iopub.execute_input":"2025-07-16T19:42:45.570630Z","iopub.status.idle":"2025-07-16T19:42:45.575141Z","shell.execute_reply.started":"2025-07-16T19:42:45.570591Z","shell.execute_reply":"2025-07-16T19:42:45.574424Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"def train_model_v1(model, train_loader, val_loader, optimizer,\n          device, num_epochs, eval_freq, eval_iter,\n          start_context, tokenizer):\n\n    # initlization of lists to track losses and token seen\n    train_losses = val_losses = track_tokens_seen = []\n    tokens_seen, global_step = 0, -1\n\n    # Main loop\n    # For each epoch\n    for epoch in range(num_epochs):\n        model.train()\n\n        # For each batch in epoch\n        for input_batch, target_batch in train_loader:\n            # Reset loss gradients from previous batch\n            optimizer.zero_grad()\n\n            # calculate loss\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n\n            # compute gradient loss\n            loss.backward()\n\n            # update weights\n            optimizer.step()\n\n            # update tokens seen at step\n            tokens_seen += input_batch.numel()\n\n            # update epoch count\n            global_step += 1\n\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter\n                )\n\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Epoch: {epoch+1} (Step {global_step:06d}): \"\n                      f\"Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n\n        # generate output from tokens for visualization after each epoch\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:48.005665Z","iopub.execute_input":"2025-07-16T19:42:48.005942Z","iopub.status.idle":"2025-07-16T19:42:48.012176Z","shell.execute_reply.started":"2025-07-16T19:42:48.005919Z","shell.execute_reply":"2025-07-16T19:42:48.011414Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def train_model_v2(model, train_loader, val_loader, optimizer,\n          scheduler, device, num_epochs, eval_freq, eval_iter,\n          start_context, tokenizer):\n\n    # initlization of lists to track losses and token seen\n    train_losses = val_losses = track_tokens_seen = []\n    tokens_seen, global_step = 0, -1\n\n    # Main loop\n    # For each epoch\n    for epoch in range(num_epochs):\n        model.train()\n\n        total_train_loss = 0\n\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n\n        # For each batch in epoch\n        for input_batch, target_batch in progress_bar:\n            # Reset loss gradients from previous batch\n            optimizer.zero_grad()\n\n            # calculate loss\n            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n\n            # compute gradient loss\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # update weights\n            optimizer.step()\n            scheduler.step()\n\n            total_train_loss += loss.item()\n            # update tokens seen at step\n            tokens_seen += input_batch.numel()\n\n            # update step count\n            # global_step += 1\n            progress_bar.set_postfix({\"loss\": f\"{loss.item():.3f}\"})\n\n        # Evaluation after each epoch\n        model.eval()\n        with torch.no_grad():\n            val_loss = calculate_loss_loader(val_loader, model, device)\n\n        # avg training loss for each epoch\n        avg_train_loss = total_train_loss / len(train_loader)\n\n        train_losses.append(avg_train_loss)\n        val_losses.append(val_loss)\n\n        print(f\"Epoch {epoch+1:02d} | Avg Train Loss: {avg_train_loss:.3f} | Val loss: {val_loss:.3f}\")\n\n        # generate output from tokens for visualization after each epoch\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:43:48.498265Z","iopub.execute_input":"2025-07-16T19:43:48.498867Z","iopub.status.idle":"2025-07-16T19:43:48.505290Z","shell.execute_reply.started":"2025-07-16T19:43:48.498841Z","shell.execute_reply":"2025-07-16T19:43:48.504547Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"if torch.cuda.is_available():\n   device = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n   device = torch.device(\"mps\")\nelse:\n   device = torch.device(\"cpu\")\n\nprint(f\"Using {device} device.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:42:53.921033Z","iopub.execute_input":"2025-07-16T19:42:53.921880Z","iopub.status.idle":"2025-07-16T19:42:53.990187Z","shell.execute_reply.started":"2025-07-16T19:42:53.921844Z","shell.execute_reply":"2025-07-16T19:42:53.989372Z"}},"outputs":[{"name":"stdout","text":"Using cuda device.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\nnum_epochs = 5\n\ntotal_training_steps = num_epochs * len(train_loader)\nwarmup_steps = int(total_training_steps * 0.1)\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_training_steps,\n)\n\ntrain_losses, val_losses, tokens_seen = train_model_v2(\n    model, train_loader, val_loader, optimizer, scheduler, \n    device, num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n    start_context=\"Every effort moves you\", tokenizer=tokenizer\n)\n\nend_time = time.time()\nexecution_time = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time:.2f} minutes.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:45:39.036405Z","iopub.execute_input":"2025-07-16T19:45:39.036699Z","iopub.status.idle":"2025-07-16T19:49:14.560221Z","shell.execute_reply.started":"2025-07-16T19:45:39.036680Z","shell.execute_reply":"2025-07-16T19:49:14.558950Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/5:   0%|          | 0/572 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 01 | Avg Train Loss: 5.559 | Val loss: 4.755\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1401750745.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m train_losses, val_losses, tokens_seen = train_model_v2(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/236893710.py\u001b[0m in \u001b[0;36mtrain_model_v2\u001b[0;34m(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# generate output from tokens for visualization after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         generate_and_print_sample(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         )\n","\u001b[0;32m/tmp/ipykernel_36/3410524253.py\u001b[0m in \u001b[0;36mgenerate_and_print_sample\u001b[0;34m(model, tokenizer, device, start_context)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcontext_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         token_ids = generate_text(\n","\u001b[0;32m/tmp/ipykernel_36/2107787219.py\u001b[0m in \u001b[0;36mtext_to_token_ids\u001b[0;34m(text, tokenizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<|endoftext|>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mencoded_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tiktoken/core.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_tokens_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_tokens_set\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisallowed_special\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'set' and 'str'"],"ename":"TypeError","evalue":"unsupported operand type(s) for -: 'set' and 'str'","output_type":"error"}],"execution_count":35},{"cell_type":"markdown","source":"## Temperature Scaling + Selecting Top-k Logits for Output Tokens ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}